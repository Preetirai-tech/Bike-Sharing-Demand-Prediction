{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Preetirai-tech/Bike-Sharing-Demand-Prediction/blob/main/Bike_Sharing_Demand_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Bike Sharing Demand Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Type** - **Regression**\n",
        "## **Contribution**  -  **Individual (Preeti Rai)** \n",
        "<br>\n",
        "\n",
        "![Screenshot (32)](https://user-images.githubusercontent.com/102009481/177841865-7d86b86b-2849-4240-92c5-26ee85b8715b.png)\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Preetirai-tech/Bike-Sharing-Demand-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Index**\n",
        "\n",
        "1. Problem Statement\n",
        "2. Know Your Data\n",
        "3. Understanding Your Variables\n",
        "4. EDA\n",
        "5. Data Cleaning\n",
        "6. Feature Engineering\n",
        "7. Model Building\n",
        "8. Model Implementaion.\n",
        "9. Conclusion"
      ],
      "metadata": {
        "id": "GbCUWV3mBdV3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DVXpM2vHBWPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's Begin !**"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The \"Bike Sharing Demand Prediction\" project addresses the challenge faced by bike sharing companies in accurately forecasting and meeting the fluctuating demand for bike rentals. The unpredictable nature of bike rental demand poses difficulties in managing fleet size, allocating resources, and providing optimal customer service. Without a reliable demand prediction system, bike sharing companies often struggle to ensure a sufficient number of bikes are available during peak periods, resulting in frustrated customers and missed revenue opportunities. Conversely, overestimating demand leads to surplus bikes and unnecessary operational costs. Therefore, the problem at hand is to develop a robust machine learning model that can accurately forecast bike rental demand, enabling companies to optimize fleet management, allocate resources efficiently, and deliver an exceptional user experience while maximizing profitability.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Know Your Data**"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "# data visualisation and manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zVvt-sgnQuxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Seoul Bike Dataset\n",
        "bike_sharing_df = pd.read_csv(\"/content/drive/MyDrive/AlmaBetter/Capstone Project/Supervised: Regression/SeoulBikeData.csv\", \n",
        "                              encoding ='latin')"
      ],
      "metadata": {
        "id": "ZmTNL8L-Rfnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows\n",
        "bike_sharing_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the last 5 rows\n",
        "bike_sharing_df.tail()"
      ],
      "metadata": {
        "id": "TbmZrGFQKI-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check ramdom sample\n",
        "bike_sharing_df.sample(5)"
      ],
      "metadata": {
        "id": "rrNAMU4NamsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensions of the dataset\n",
        "bike_sharing_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 8760 rows and 14 columns in this dataset."
      ],
      "metadata": {
        "id": "B5rNNJwULAwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of columns in the data\n",
        "bike_sharing_df.columns"
      ],
      "metadata": {
        "id": "CLTMBSeCLSwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get information about the dataset\n",
        "bike_sharing_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n",
        "- **Float64 datatype:** 6 columns ie ``Temperature(°C)``,  ``Wind speed (m/s``, ``Dew point temperature(°C)``, ``Solar Radiation(MJ/m2)``, ``Rainfall(mm)``, ``Snowfall(cm)`` & ``Seasons``. \n",
        "- **Int64 datatype:** 4 columns ie ``Rented Bike``, ``Count, Hour``, ``Humidity(%)`` & ``Visibility(10m)``.\n",
        "- **Object datatype:** 4 columns ie ``Date``, ``Seasons``, ``Holidays`` & ``Functioming Day``.**              \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DqeIm3N55bFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of unique values in each columns\n",
        "bike_sharing_df.nunique()"
      ],
      "metadata": {
        "id": "oy95AQymUu-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above result, it is observed that this datasets contains bike rental data of 1 year (since there are 365 unique values in a Date column)**"
      ],
      "metadata": {
        "id": "prSjyx9lX59T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print('The number of duplicated values in each column:' , bike_sharing_df.duplicated().sum())"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "\n",
        "bike_sharing_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.matrix(bike_sharing_df)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above results, it is evident that there are no missing values in the dataset .**"
      ],
      "metadata": {
        "id": "3LA0EmxWeqAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **The dataset contains 8760 rows and 14 columns.**\n",
        "- **There are 6 columns of datatype float64, 4 columns of datatype int64 and 4 columns of datatype object.**\n",
        "- **There are no missing and duplicate values in the dataset.**\n",
        "- **The dataset contains bike rental data of 1 year.**\n",
        "- **Input features: ``Date``, ``Hour``, ``Temperature(°C)``, ``Humidity(%)``, ``Wind speed (m/s)``,``Visibility (10m)``, ``Dew point temperature(°C)``, ``Solar Radiation (MJ/m2)``, ``Rainfall(mm)``, ``Snowfall (cm)``, ``Season``, ``Holiday`` & ``Functioning Day``**\n",
        "- **Target feature: ``Rented Bike Count``** "
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Understanding Your Variables**"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "bike_sharing_df.columns.tolist()"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical summary of the dataset\n",
        "bike_sharing_df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- ``Rainfall``: 75% of the datapoints recorded were of below 0 cm ie no rainfall. Only 25% records was above 0.\n",
        "- ``Snowfall``: 75% of the datapoints were recorded were of 0 ie No Snowfall. Only 25% was above 0."
      ],
      "metadata": {
        "id": "AwG5TGBgiSI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_sharing_df['Seasons'].value_counts()"
      ],
      "metadata": {
        "id": "H9UGxuDnx5-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_sharing_df['Functioning Day'].value_counts()"
      ],
      "metadata": {
        "id": "0OZ9G9YTyj84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_sharing_df['Holiday'].value_counts()"
      ],
      "metadata": {
        "id": "zgt132dOy-hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.\n",
        "\n",
        "**Attribute Information:**\n",
        "- **Date:** The specific calendar date for the bike rental record. <br>\n",
        "- **Rented Bike Count:** The number of bikes rented during a specific time interval.\n",
        "- **Temperature:** The temperature in Celsius at the time of the bike rental.\n",
        "- **Humidity:** The relative humidity percentage at the time of the bike rental.\n",
        "- **Wind Speed:** The speed of the wind in meters per second at the time of the bike rental.\n",
        "- **Visibility:** The visibility in meters at the time of the bike rental.\n",
        "- **Dew Point Temperature:** The temperature at which air becomes saturated and dew forms at the time of the bike rental.\n",
        "- **Solar Radiation:** The amount of solar radiation in mega-joules per square meter at the time of the bike rental.\n",
        "- **Rainfall:** The amount of rainfall in millimeters at the time of the bike rental.\n",
        "- **Snowfall:** The amount of snowfall in centimeters at the time of the bike rental.\n",
        "- **Seasons:** The four seasons (Spring, Summer, Autumn, Winter) corresponding to the bike rental record.\n",
        "\n",
        "- **Holiday:** A categorical variable indicating whether the day of the bike rental record is a holiday or not. It has two possible values: \"Holiday\" and \"No Holiday\". The \"Holiday\" value represents a day that is recognized as a holiday, while the \"No Holiday\" value represents a regular day that is not a designated holiday.\n",
        "\n",
        "- **Functioning Day:** A categorical variable indicating whether the bike rental service was functioning on the day of the record. It has two possible values: \"Yes\" and \"No\". The \"Yes\" value indicates that the bike rental service was operational and functioning normally on that day. Conversely, the \"No\" value indicates that the bike rental service was not operating, potentially due to maintenance, strikes, or other reasons."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable\n",
        "for i in bike_sharing_df.columns.to_list():\n",
        "  print('Number of unique values in', i, 'is', bike_sharing_df[i].nunique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Date column of datatype Object to Datetime datatype\n",
        "bike_sharing_df['Date'] = pd.to_datetime(bike_sharing_df['Date'], dayfirst = True)"
      ],
      "metadata": {
        "id": "O8DOG67sj7QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting day name feature\n",
        "bike_sharing_df['Day'] = bike_sharing_df['Date'].dt.day_name()\n",
        "\n",
        "# Extracting month name feature\n",
        "bike_sharing_df['Month'] = bike_sharing_df['Date'].dt.month_name()\n",
        "\n",
        "# Extracting year feature\n",
        "bike_sharing_df['Year'] = bike_sharing_df['Date'].dt.year\n",
        "\n"
      ],
      "metadata": {
        "id": "bMqeligPj7Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Date column\n",
        "bike_sharing_df.drop(columns = ['Date'], inplace = True)"
      ],
      "metadata": {
        "id": "kzLQf1vNGG8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename the complex columns name\n",
        "bike_sharing_df = bike_sharing_df.rename(columns={\n",
        "                                'Temperature(°C)':'Temperature',\n",
        "                                'Humidity(%)':'Humidity',\n",
        "                                'Wind speed (m/s)':'Wind Speed',\n",
        "                                'Visibility (10m)':'Visibility',\n",
        "                                'Dew point temperature(°C)':'Dew point temperature',\n",
        "                                'Solar Radiation (MJ/m2)':'Solar Radiation',\n",
        "                                'Rainfall(mm)':'Rainfall',\n",
        "                                'Snowfall (cm)':'Snowfall',\n",
        "                              })\n",
        "     "
      ],
      "metadata": {
        "id": "Sk50DpOnFORs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_sharing_df.sample(3)"
      ],
      "metadata": {
        "id": "dVSBeZIErgQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Hour and Year columns from integer to object\n",
        "bike_sharing_df['Hour'] = bike_sharing_df['Hour'].astype('object')\n",
        "bike_sharing_df['Year'] = bike_sharing_df['Year'].astype('object')"
      ],
      "metadata": {
        "id": "CVhmxFQjJwNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is EDA?**\n",
        "\n",
        "- EDA stands for Exploratory Data Analysis. It is a crucial step in the data analysis process that involves exploring and understanding the characteristics, patterns, and relationships within a dataset. EDA aims to uncover insights, identify patterns, detect outliers, and gain a deeper understanding of the data before conducting further analysis or modeling."
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.1 Numeric and Categorical Features**"
      ],
      "metadata": {
        "id": "Y_NBT2gxSGxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing data into numerical and categorical features\n",
        "\n",
        "categorical_features = bike_sharing_df.select_dtypes(include = 'object')\n",
        "numerical_features = bike_sharing_df.select_dtypes(exclude = 'object')\n"
      ],
      "metadata": {
        "id": "oUzZPHltS123"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features.head(2)"
      ],
      "metadata": {
        "id": "A5himtO5SFx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features.head(2)"
      ],
      "metadata": {
        "id": "CUDL8WbVSFvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2 Univariate Analysis**"
      ],
      "metadata": {
        "id": "9VEsMM3aVUvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2.1 Data Distribution of Numeric features**"
      ],
      "metadata": {
        "id": "9P9A3L3lVkFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# figsize\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "# title\n",
        "plt.suptitle('Data Distribution of Numeric Features', fontsize = 20, fontweight = 'bold', y=1.02)\n",
        "\n",
        "for i, col in enumerate(numerical_features):\n",
        "  # subplots 3 rows and 3 columns\n",
        "  plt.subplot(3, 3, i+1 )\n",
        "\n",
        "  # dist plot\n",
        "  sns.distplot(bike_sharing_df[col])\n",
        "  plt.axvline(bike_sharing_df[col].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  plt.axvline(bike_sharing_df[col].median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "\n",
        "  plt.title(col)\n",
        "  plt.tight_layout()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZAAm5C3ASFsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- For numerical features, we can see that the majority of distributions are right-skewed and few are left-skewed.\n",
        "- **Right-skewed columns:** ``Rented Bike Count``, ``Wind speed``, ``Solar Radiation``, ``Rainfall`` & ``Snowfall``.\n",
        "- **Left-skewed columns:** ``Visibility`` & ``Dew point temperature`` "
      ],
      "metadata": {
        "id": "i6O_taqWgxuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2.2 Outlier Analysis of Numeric features**"
      ],
      "metadata": {
        "id": "OGcT-QQyseeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# figsize\n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "# title\n",
        "plt.suptitle('Outlier Analysis of Numeric features', fontsize = 20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i, col in enumerate(numerical_features):\n",
        "  # subplots 3 rows, 3 columns\n",
        "  plt.subplot(3,3, i+1)\n",
        "\n",
        "  # boxplots\n",
        "  sns.boxplot(numerical_features[col])\n",
        "  \n",
        "  plt.title(col)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "bBcruxdPSFmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- Outliers are visible in most of the numerical columns.\n",
        "- These columns are ``Rented Bike Count``, ``Wind Speed``, ``Solar Radiation``, ``Rainfall`` & ``Snowfall``.\n",
        "- The columns like ``Temperature``, ``Humidity``, ``Visibility`` & ``Dew point temperature`` do not contain any outliers."
      ],
      "metadata": {
        "id": "uiJrOZ6Vu85x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2.3 Univariate Analysis of Categorical Features**"
      ],
      "metadata": {
        "id": "QH3INnF3yJAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# figure\n",
        "plt.figure(figsize = (20,8))\n",
        "\n",
        "# title\n",
        "plt.suptitle('Univariate Analysis of Categorical Features', fontsize = 20, fontweight = 'bold', y = 1.02)\n",
        "\n",
        "for i, col in enumerate(categorical_features):\n",
        "  # subplots of \n",
        "  plt.subplot(3,3, i+1)\n",
        "\n",
        "  # Countplots\n",
        "  sns.countplot(x = categorical_features[col])\n",
        "  \n",
        "  plt.xticks(rotation ='vertical')\n",
        "  plt.title(col)\n",
        "  plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "i72DWI3_SFgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- Every hour has an equal number of counts in the dataset.\n",
        "- Every season has almost equal number of counts.\n",
        "- Dataset has more records of No holiday than a holiday which is obvious as most of the days are working days.\n",
        "- Dataset has more records of Functioning Day than no functioning day which is obvious as most of the days are working days.\n",
        "- Except Friday, other Days have equal number of counts in the dataset.\n",
        "- Months like April, June, September, November & February have a slightly low number of count comparted to other months.\n",
        "- More data was colected in the year 2018 than 2017."
      ],
      "metadata": {
        "id": "kpwga4or7MDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.3 Bivariate and Multivariate Analysis**"
      ],
      "metadata": {
        "id": "gIrxjtTWBu3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3.1 Analysis between target variable and numerical features**"
      ],
      "metadata": {
        "id": "GN7B65qoB3fe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify patterns and trends in numerical features\n",
        "\n",
        "plt.suptitle('Bivariate Analysis of Numerical features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "\n",
        "for i in numerical_features:\n",
        "  plt.figure(figsize=(15,6))\n",
        "  sns.lineplot(x= i, y='Rented Bike Count', data = numerical_features, palette='Grouped')\n",
        "  plt.title(f\"Bike Demand over {i}\");\n",
        "  print('\\n')\n",
        "  plt.xticks(rotation = 45)\n"
      ],
      "metadata": {
        "id": "JO5dOkuxWX3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize = (15, 10))\n",
        "\n",
        "# title\n",
        "plt.suptitle('Bivariate Analysis of Numerical features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for index, col in enumerate(numerical_features):\n",
        "\n",
        "  # subplots of 3 rows and 3 columns\n",
        "  plt.subplot(3,3, index+1)\n",
        "\n",
        "  # line plots\n",
        "  sns.scatterplot(x = numerical_features[col], y = numerical_features['Rented Bike Count'])\n",
        "\n",
        "  plt.title(f'Bike Damand Over {col}')\n",
        "  plt.xticks(rotation = 45)\n",
        "  plt.tight_layout()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yD4LU_vv_9Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3.2 Bivariate Analysis of Categorical Features**"
      ],
      "metadata": {
        "id": "h0v94LTjJRQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting number of category present in each feature with respect to target feature  \n",
        "\n",
        "# figsize\n",
        "plt.figure(figsize=(15,10))\n",
        "# title\n",
        "plt.suptitle('Bivariate Analysis of Categorical Features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i,col in enumerate(categorical_features):      \n",
        "   # subplots of 3 rows and 3 columns\n",
        "  plt.subplot(3, 3, i+1)                                \n",
        "  a = bike_sharing_df.groupby(col)[['Rented Bike Count']].mean().reset_index()\n",
        "\n",
        "  # barplot\n",
        "  sns.barplot(x=a[col], y=a['Rented Bike Count'])\n",
        "  # x-axis label\n",
        "  plt.title(f'Average bike rentals across {col}')\n",
        "  plt.xticks(rotation = 'vertical')\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "w_SRg4IfNbVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**:\n",
        "- **Hours:** The highest demand is in hours from say 7-10 and from 15-19. This could be the reason that in most of the metroploitan cities this is the peak office time and so more people would be renting bikes.import itertools\n",
        "- **Seasons:** Summer season had the higest Bike Rent Count. People are more likely to rent bikes in summer. Bike rentals in winter is very less compared to other seasons.\n",
        "- **Holidays:** High number of bikes were rented on No Holidays.*\n",
        "- **Functioning Day:** On 'No Functioning Day, only 295 bikes were rented. Hence, this column does not add value to our prediction, we can drop this column in the next steps.*\n",
        "- **Day:** Most of the bikes were rented on Weekdays compared to weekends.*\n",
        "- **Month:** From March Bike Rent Count started increasing and it was highest in June.*"
      ],
      "metadata": {
        "id": "IdFBRiOCmHLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3.3 Multivariate Analysis**"
      ],
      "metadata": {
        "id": "JcSUOBHijcjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysing bike demand with respect to hour and different third value\n",
        "\n",
        "for i in categorical_features:\n",
        "  if i == 'Hour':\n",
        "    pass\n",
        "  else:\n",
        "    plt.figure(figsize=(15,8))\n",
        "    sns.lineplot(x= bike_sharing_df[\"Hour\"], y= bike_sharing_df['Rented Bike Count'], hue= bike_sharing_df[i], marker ='o')\n",
        "    plt.title(f\"Bike Demand over Hour wrt to {i}\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rwjsX1CGXUrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bar plot for seasonwise monthly distribution of Rented_Bike_Count\n",
        "fig,ax=plt.subplots(figsize=(15,8))\n",
        "sns.barplot(x='Month',y='Rented Bike Count',data= bike_sharing_df, hue='Seasons',ax=ax);\n",
        "ax.set_title('Season-wise monthly Rented Bike Count');\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "ldpNWgR_d7ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "- The above regression plots for the numerical features indicate that the columns ``Temperature``, ``Wind_speed``, ``Visibility``, ``Dew_point_temperature`` & ``Solar_Radiation`` are positively correlated with the target variable, ie , with an increase in these features results in an increase in rented bike count.\n",
        "- On the other hand, ``Rainfall``, ``Snowfall`` & ``Humidity`` are negatively correlated with the target variable, indicating that with an increase in these features results in a decrease in rented bike count."
      ],
      "metadata": {
        "id": "NVBUpljMIKP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Data Cleaning**"
      ],
      "metadata": {
        "id": "Jh33RSOH01Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is data cleaning?**\n",
        "Data cleaning, also known as data cleansing or data scrubbing, refers to the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in a dataset. It involves handling missing data, removing duplicates, addressing outliers, standardizing formats, resolving inconsistencies, and validating data. Data cleaning ensures that the data is accurate, complete, and reliable for analysis or machine learning purposes."
      ],
      "metadata": {
        "id": "4mmVrmyIt_SQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.1 Handling Missing Values**"
      ],
      "metadata": {
        "id": "ya3j49rvKPpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "bike_sharing_df.isnull().sum()"
      ],
      "metadata": {
        "id": "1UjJoym3Lgi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see there are no null values present in our dataset and therefore we are good to go.**"
      ],
      "metadata": {
        "id": "sja2kH_FL_5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2 Handling duplicate values**"
      ],
      "metadata": {
        "id": "5yaKasKuMn8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for duplicate values\n",
        "bike_sharing_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "Ddjy76Q3L-t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see there are no duplicate values, so we can move ahead.**"
      ],
      "metadata": {
        "id": "-gq5YzdPM4_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.3 Handling Outliers**"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outliers are data points that deviate significantly from the majority of the data and can have a disproportionate impact on statistical analysis or modeling.**"
      ],
      "metadata": {
        "id": "D9rTqAqe8C_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a boxplot to detect columns with outliers\n",
        "# figsize\n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "# title\n",
        "plt.suptitle('Outlier Analysis of Numeric features', fontsize = 20, fontweight='bold', y=1.02)\n",
        "\n",
        "for index , col in enumerate(numerical_features):\n",
        "  # subplots 3 rows, 3 columns\n",
        "  plt.subplot(3,3, index+1)\n",
        "\n",
        "  # boxplots\n",
        "  sns.boxplot(numerical_features[col])\n",
        "  \n",
        "  plt.title(col)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "LFYMnpKBL-q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we can see that the columns that contain outliers are Rented Bike Count``, ``Windspeed``, ``Solar Radiation``, ``Rainfall`` & ``Snowfall``**"
      ],
      "metadata": {
        "id": "p17-SQdgP3Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a list of columns that contains outliers\n",
        "outlier_cols = ['Rented Bike Count', 'Wind Speed', 'Solar Radiation', 'Rainfall','Snowfall']\n",
        "outlier_cols"
      ],
      "metadata": {
        "id": "Qv6RNuAVf-Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ranges(data, column):\n",
        "\n",
        "  # Skip categorical columns\n",
        "  if data[column].dtype == 'object':\n",
        "    return None, None  \n",
        "  else:\n",
        "    # Calculate quartiles\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    \n",
        "    # Calculate IQR\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    # Calculate upper and lower ranges\n",
        "    upper_range = Q3 + 1.5 * IQR\n",
        "    lower_range = Q1 - 1.5 * IQR\n",
        "    \n",
        "    return upper_range, lower_range"
      ],
      "metadata": {
        "id": "u8nUZJWmToVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_ranges(numerical_features, 'Rented Bike Count')"
      ],
      "metadata": {
        "id": "ONydWAROUrDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify potential outliers\n",
        "plt.figure(figsize = (15,10))\n",
        "\n",
        "for index, col in enumerate(outlier_cols):\n",
        "\n",
        "  # Apply calculate_ranges function to get upper bound and lower bound\n",
        "  upper_bound, lower_bound = calculate_ranges(bike_sharing_df, col)\n",
        "\n",
        "  # Identify potential outliers\n",
        "  outliers = bike_sharing_df[(bike_sharing_df[col] > upper_bound) | (bike_sharing_df[col] < lower_bound)]\n",
        "\n",
        "# Visualize the potential outliers\n",
        "  #plt.figure(figsize=(8, 6))\n",
        "  \n",
        "  # subplots 3 rows, 3 columns\n",
        "  plt.subplot(3,3, index+1)\n",
        "  plt.hist(bike_sharing_df[col], bins=30, color='lightblue', edgecolor='black', label='Data')\n",
        "  plt.hist(outliers[col], bins=10, color='red', edgecolor='black', label='Potential Outliers')\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('Frequency')\n",
        "  \n",
        "  plt.suptitle('Distribution of Numerical features with Potential Outliers', fontsize = 20, fontweight='bold', y=1.02)\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  #plt.show()"
      ],
      "metadata": {
        "id": "kqUqKhY8VMAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to count the total number of outliers in each column\n",
        "\n",
        "def count_outliers(data):\n",
        "    # Initialize a variable to store the total number of outliers\n",
        "    outlier_count = {}\n",
        "\n",
        "    # Loop through each column in the list containing outliers\n",
        "    for col in outlier_cols:\n",
        "\n",
        "        # Calculate the upper and lower ranges\n",
        "        upper_range, lower_range = calculate_ranges(data, col)\n",
        "\n",
        "        # Count the number of outliers in the column\n",
        "        outlier_count[col] = len(data[(data[col] > upper_range) | (data[col] < lower_range)])\n",
        "\n",
        "    return outlier_count"
      ],
      "metadata": {
        "id": "S3J1vnu8Wpe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of outliers in each column\n",
        "count_outliers(bike_sharing_df)"
      ],
      "metadata": {
        "id": "arkAkzWJXnLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**:\n",
        "- It is not wise to trim the entire outliers as we tend to lose many data points. Hence we are not simply removing the outlier instead of that we are using the clipping method."
      ],
      "metadata": {
        "id": "Hw08_6knlXnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we do not want any transformation in our target variable as it is possible to have outlier in Seoul Environment\n",
        "# Removing rainfall and snowfall as it may remove important information as these 2 columns are highly skewed.\n",
        "\n",
        "num_features = ['Temperature', 'Humidity', 'Wind Speed', 'Visibility', 'Dew point temperature', 'Solar Radiation']\n"
      ],
      "metadata": {
        "id": "GrdsETrDUYEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clipping Method:** In this method, we set a cap on our outliers data, which means that if a value is higher than or lower than a certain threshold, all values will be considered outliers. This method replaces values that fall outside of a specified range with either the minimum or maximum value within that range."
      ],
      "metadata": {
        "id": "4momdY3kH-VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we are going to replace the datapoints with upper and lower bound of all the outliers\n",
        "\n",
        "def clip_outliers(bike_df):\n",
        "    #numerical_features = ['Temperature', 'Humidity', 'Wind Speed', 'Visibility', 'Dew point temperature', 'Solar Radiation']\n",
        "  \n",
        "    for col in num_features:\n",
        "        # Using IQR method to define the range of upper and lower limits\n",
        "        q1 = bike_df[col].quantile(0.25)\n",
        "        q3 = bike_df[col].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        \n",
        "        # Replacing the outliers with the upper and lower bounds\n",
        "        bike_df[col] = bike_df[col].clip(lower_bound, upper_bound)\n",
        "    \n",
        "    return bike_df\n"
      ],
      "metadata": {
        "id": "z-qa6ayBnerH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = bike_sharing_df.copy()\n",
        "# using the function to treat outliers\n",
        "new_df = clip_outliers(new_df)"
      ],
      "metadata": {
        "id": "h1t_lOpHnjfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the boxplot after outlier treatment\n",
        "\n",
        "# figsize\n",
        "plt.figure(figsize=(15,8))\n",
        "# title\n",
        "plt.suptitle('Outlier Analysis of Numerical Features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i,col in enumerate(num_features):\n",
        "  # subplot of 3 rows and 2 columns\n",
        "  plt.subplot(3, 2, i+1)            \n",
        "\n",
        "  # countplot\n",
        "  sns.boxplot(new_df[col])\n",
        "  # x-axis label\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "1Kg_eME-pT0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for distribution after treating outliers.\n",
        "\n",
        "# figsize\n",
        "plt.figure(figsize=(15,6))\n",
        "# title\n",
        "plt.suptitle('Data Distibution of Numerical Features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i,col in enumerate(num_features):\n",
        "  # subplots 3 rows, 2 columns\n",
        "  plt.subplot(3, 2, i+1)                      \n",
        "\n",
        "  # dist plots\n",
        "  sns.distplot(new_df[col])  \n",
        "  # x-axis label\n",
        "  plt.xlabel(col)\n",
        "  plt.tight_layout()  "
      ],
      "metadata": {
        "id": "y-lEhXhDoiPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can also observe some shifts in the distribution of the data after treating outliers. Some of the data were skewed before handling outliers, but after doing so, the features almost follow the normal distribution. Therefore, we are not utilizing the numerical feature transformation technique.**"
      ],
      "metadata": {
        "id": "zKiIa_93ptJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Feature Engineering**"
      ],
      "metadata": {
        "id": "G3O1wkFI8vq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Feature engineering is the process of transforming raw data into a set of meaningful, informative, and predictive features that can be used to train machine learning models. It involves selecting, creating, or modifying features in the dataset to enhance the performance and effectiveness of the models.\n",
        "- Feature engineering is a critical step in machine learning because the quality and relevance of features can significantly impact the model's performance. Well-engineered features can help capture relevant patterns, relationships, and structures in the data, enabling the model to make accurate predictions or classifications"
      ],
      "metadata": {
        "id": "YERopvg0-F_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.1 Regression Plot**"
      ],
      "metadata": {
        "id": "mdnSveS18-So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Linearity of all numerical features with our target variable\n",
        "\n",
        "# figsize\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# title\n",
        "plt.suptitle('Regression Analysis of Numerical features', fontsize=20, fontweight='bold', y=1.02)\n",
        "\n",
        "for i, col in enumerate(numerical_features):\n",
        "\n",
        "  # subplots of 3 rows and 3 columns\n",
        "  plt.subplot(3, 3, i+1) \n",
        "\n",
        "  # regression plots\n",
        "  sns.regplot(x= numerical_features[col], y = numerical_features['Rented Bike Count'], scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\n",
        "    \n",
        "  plt.title(f'Dependend variable and {col}')\n",
        "  plt.tight_layout()\n",
        "     "
      ],
      "metadata": {
        "id": "knvJncDNSFUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most of the numerical features are positively correlated to our target variable.**"
      ],
      "metadata": {
        "id": "x2AxgmDn9Odf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.2 Correlation Coefficient and Heatmap**"
      ],
      "metadata": {
        "id": "K00UrYKN9g15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The correlation coefficient is a statistical measure that quantifies the strength and direction of the linear relationship between two variables. It provides an indication of how closely the variables are related to each other.\n",
        "The correlation coefficient, often denoted as \"r,\" ranges from -1 to 1.\n",
        "- A correlation coefficient of 1 indicates a perfect positive linear relationship, where the variables increase or decrease together with a constant slope.\n",
        "- A correlation coefficient of -1 indicates a perfect negative linear relationship, where the variables move in opposite directions with a constant slope.\n",
        "- A correlation coefficient of 0 indicates no linear relationship between the variables.\n",
        "- The correlation coefficient is calculated using the covariance between the variables divided by the product of their standard deviations. \n",
        "- The correlation coefficient provides insight into the strength and direction of the relationship between variables. \n",
        "- However, it only measures linear relationships and does not capture other types of associations, such as nonlinear or complex dependencies.\n"
      ],
      "metadata": {
        "id": "17He_ixh-2tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap relative to all numeric columns\n",
        "corr_matrix = bike_sharing_df.corr()\n",
        "mask = np.array(corr_matrix)\n",
        "mask[np.tril_indices_from(mask)] = False\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, cbar=True, vmax=0.8, vmin=-0.8, cmap='RdYlGn')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RYjXeHjHA-yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(2,4), dpi=150)\n",
        "sns.heatmap(bike_sharing_df.corr()[[\"Rented Bike Count\"]].sort_values\n",
        "            (by=\"Rented Bike Count\", ascending=False)[1:],annot=True)\n",
        "plt.title('Features Correlating with Rented Bike Count', fontsize=10, fontweight='bold', y=1.02);\n",
        "\n",
        "#heatmap.set_title('Features Correlating with Rented Bike Count', fontdict={'fontsize':18}, pad=16);"
      ],
      "metadata": {
        "id": "AbSvWkDIPv6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above graph we could see that the columns Temperature and Dew Point Temperature are highly corelated. We can drop one of them. As the corelation between Temperature and our dependent variable \"Bike Rented Count\" is high compared to Dew Point Temperature. So we will Keep the Temperature column and drop the Dew Point Temperature column.**"
      ],
      "metadata": {
        "id": "OEfTHxOUDvCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# droping Dew point temperature column due to multi-collinearity\n",
        "\n",
        "new_df.drop('Dew point temperature', axis=1, inplace=True)\n",
        "     "
      ],
      "metadata": {
        "id": "y4UUxKhJEKWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.3 VIF**"
      ],
      "metadata": {
        "id": "s5ttalRXJHI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- VIF, which stands for Variance Inflation Factor, is a measure used in regression analysis to assess multicollinearity among predictor variables.\n",
        "- Multicollinearity occurs when predictor variables in a regression model are highly correlated with each other, which can cause issues in interpreting the individual effects of the variables and can lead to unstable and unreliable model estimates.\n",
        "- The VIF quantifies the extent to which the variance of the estimated regression coefficient is inflated due to multicollinearity. \n",
        "- It measures how much the variance of a particular predictor variable's estimated coefficient is increased compared to if that variable were uncorrelated with the other predictor variables in the model.\n",
        "\n",
        "Interpreting VIF values:\n",
        "- A VIF of 1 indicates no multicollinearity, meaning the predictor variable is not correlated with the other predictors.\n",
        "- A VIF greater than 1 suggests some degree of multicollinearity, where higher values indicate stronger correlation with other predictors.\n",
        "- A commonly used threshold is a VIF value of 5 or 10. Variables with VIF values exceeding these thresholds are considered to have high multicollinearity and may need to be addressed.\n",
        "\n",
        "By examining VIF values, researchers can identify predictor variables that contribute to multicollinearity and take appropriate actions, such as removing highly correlated variables, combining variables, or gathering additional data to mitigate the multicollinearity issue."
      ],
      "metadata": {
        "id": "v1RrAtwXJb96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# function to calculate Multicollinearity\n",
        "\n",
        "def calculate_vif(X):\n",
        "\n",
        "  # For each X, calculate VIF and save in dataframe\n",
        "  vif = pd.DataFrame()\n",
        "  vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "  vif[\"features\"] = X.columns\n",
        "  \n",
        "  return vif"
      ],
      "metadata": {
        "id": "9vrQ6Nm-EKSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multicollinearity result\n",
        "\n",
        "calculate_vif(new_df[[i for i in new_df.describe().columns if i not in ['Rented Bike Count','Date']]])"
      ],
      "metadata": {
        "id": "Z00K85WQEKQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These are our final numerical variables to be considered for model building.**"
      ],
      "metadata": {
        "id": "0i8kjTDLLv9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.4 Encoding**"
      ],
      "metadata": {
        "id": "FzBvF0bQMAAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding refers to the process of converting categorical variables into numerical representations that can be understood and processed by machine learning algorithms. Since many machine learning algorithms require numerical inputs, encoding categorical variables becomes necessary.\n",
        "\n",
        "Common techniques for encoding categorical variables in machine learning include:\n",
        "\n",
        "1. One-Hot Encoding: This technique creates binary columns for each category in a categorical variable. Each category is represented by a separate binary column, where a value of 1 indicates the presence of that category and 0 indicates its absence. This approach allows algorithms to interpret categorical variables without assuming any ordinal relationship among the categories.\n",
        "\n",
        "2. Label Encoding: Label encoding assigns a unique numerical label to each category in a categorical variable. Each category is mapped to a corresponding numerical value. However, caution should be exercised with label encoding, as it may introduce an arbitrary ordinal relationship between the categories, which may not be appropriate for some algorithms.\n",
        "\n",
        "3. Ordinal Encoding: Similar to label encoding, ordinal encoding assigns numerical labels to categories. However, in ordinal encoding, the labels are assigned in a way that represents an ordered relationship between the categories. This can be useful when there is a natural order or hierarchy among the categories.\n",
        "\n",
        "4. Target Encoding: Target encoding replaces each category with the mean (or another statistical measure) of the target variable within that category. Target encoding can be helpful when the relationship between the categorical variable and the target variable is important for prediction."
      ],
      "metadata": {
        "id": "J9VASTCJ29k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# droping Year columns as it does not account for any information addition\n",
        "\n",
        "new_df.drop(['Year'], axis=1, inplace = True)\n",
        "categorical_features.drop('Year', axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "zO5tUKgVxZXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each categorical variable.\n",
        "for i in categorical_features:\n",
        "  print(\"Number of unique values in\", i, \"is\" , new_df[i].nunique())"
      ],
      "metadata": {
        "id": "Ueo4ELdX0UYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will use one hot encoding for ``Seasons`` and Numeric encoding for ``Holiday`` and ``Functioning day``. Other columns are already encoded.**"
      ],
      "metadata": {
        "id": "CdN4G6JS4v4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab = new_df.copy()\n",
        "ab =pd.get_dummies(ab, columns=['Seasons'],prefix='Seasons',drop_first=True)"
      ],
      "metadata": {
        "id": "1tIpiLYm6Te9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ab.head()"
      ],
      "metadata": {
        "id": "lMcj7SzL67PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.get_dummies(new_df, columns = ['Seasons'], prefix='Seasons', drop_first = True)"
      ],
      "metadata": {
        "id": "r-aqRs6mLvd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head(2)"
      ],
      "metadata": {
        "id": "eo8JnBl_EKFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical Encoding for holiday and functioning_day\n",
        "\n",
        "new_df['Holiday'] = new_df['Holiday'].map({'Holiday': 1, 'No Holiday': 0})\n",
        "\n",
        "new_df['Functioning Day'] = new_df['Functioning Day'].map({'Yes': 1, 'No': 0})"
      ],
      "metadata": {
        "id": "1TOIHVTSEKDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head(2)"
      ],
      "metadata": {
        "id": "iEQawgaMEJ_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}